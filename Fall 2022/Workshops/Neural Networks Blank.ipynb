{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10/17: Neural Networks\n",
    "\n",
    "Hi everyone! In this notebook we'll be looking at Neural Networks and their applications in Machine Learning and Natural Language Processing\n",
    "\n",
    "To complete this notebook, we have the following methods for you to complete:\n",
    "\n",
    "1. `sigmoid()`\n",
    "2. `sigmoid_derivative()`\n",
    "3. `forward_prop()`\n",
    "4. `back_prop()`\n",
    "\n",
    "We'll start by building neural networks to decide if two boolean inputs are equivalent, and then extend it to recognizing handwritten digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sigmoid and the Derivative of Sigmoid\n",
    "\n",
    "The sigmoid function and its derivative are essential for the functionality of neural networks. To start, complete the function `sigmoid()`\n",
    "\n",
    "Recall from a couple of weeks ago that the formula for `sigmoid()` is:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\dpi{150}&space;\\large&space;\\frac{1}{1&space;&plus;&space;e^{-x}}\" title=\"\\large \\frac{1}{1 + e^{-x}}\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # calculate the output of the sigmoid function and return it\n",
    "    sigmoid_val = ...\n",
    "    return sigmoid_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hint</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Try to use numpy functions! You'll find <code>np.exp()</code>very useful</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test sigmoid\n",
    "if (sigmoid(0) == 0.5 and sigmoid(3.1415) == 0.9585724885979936):\n",
    "    print(\"Correct value for sigmoid!\")\n",
    "else:\n",
    "    print(\"I think you gotta fix that pal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll calculate the derivative of `sigmoid()` in the function `sigmoid_derivative()`. The derivative of `sigmoid()` is:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\dpi{150}&space;\\large&space;\\newline&space;=&space;\\frac{d}{dx}\\frac{1}{1&space;&plus;&space;e^{-x}}&space;\\newline&space;\\newline&space;=&space;-1&space;(1&space;&plus;&space;e^{-x})^{-2}&space;\\newline&space;\\newline&space;=&space;sigmoid(x)&space;*&space;(1&space;-&space;sigmoid(x))\" title=\"\\large \\newline = \\frac{d}{dx}\\frac{1}{1 + e^{-x}} \\newline \\newline = -1 (1 + e^{-x})^{-2} \\newline \\newline = sigmoid(x) * (1 - sigmoid(x))\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>You don't have to recode the formula for <code>sigmoid()</code>. Simply use the <code>sigmoid()</code> function in the earlier cell</li>\n",
    "    <li>You might find <code>np.multiply()</code> very useful</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    # calculate the derivative and return the value\n",
    "    sigmoid_deriv = ...\n",
    "    return sigmoid_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to check your derivative of sigmoid\n",
    "if (sigmoid_derivative(0) == 0.25 and sigmoid_derivative(3.1415) == 0.03971127270104303):\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"bad bad job >:(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating our Neural Network Methods\n",
    "\n",
    "Our neural network system depends on two main functions:\n",
    "1. `Forward Propogation`\n",
    "2. `Back Propogation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by implementing `forward_prop()` for our neural network\n",
    "\n",
    "You will need to complete the following steps in the method:\n",
    "\n",
    "1. Set `ones_col` equal to the correctly-sized matrix of ones\n",
    "2. Calculate `pred_val` from `formatted_inputs` and `theta`\n",
    "3. Set `curr_inputs` to the `sigmoid()` of `pred_val`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints for Step 1</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use <code>np.ones((..., ...)</code>to generate this matrix</li>\n",
    "    <li>The dimensions of <code>ones_col</code> should be <code>(m, 1)</code></li>  \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints for Step 2</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li><code>pred_val</code> is found by using matrix multiplication (<code>@</code>) with <code>formatted_inputs</code> and <code>theta</code></li>\n",
    "    <li>Make sure you're using the right dimensions! You need to specifically multiply <code>formatted_inputs</code> and <code>theta.T</code> </li>  \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hint for Step 3</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>The instructions are in the step! Let <code>curr_inputs = sigmoid(pred_val)</code></li>  \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(inputs, thetas, m):\n",
    "    # declare the values we need\n",
    "    outputs = []\n",
    "    curr_inputs = inputs\n",
    "    ones_col = ...\n",
    "    for theta in thetas:\n",
    "        # format the inputs by adding the column of ones\n",
    "        formatted_inputs = np.hstack((ones_col, curr_inputs))\n",
    "        # calculate the predicted value, and append it to the list of outputs\n",
    "        pred_val = ...\n",
    "        outputs.append(pred_val)\n",
    "        # set curr_inputs to the the sigmoid of our predicted value\n",
    "        curr_inputs = ...\n",
    "    # return our list of outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test your implementation of forward_prop\n",
    "np.random.seed(123456789)\n",
    "test_thetas = [np.random.random((2, 3)), np.random.random((1, 3))]\n",
    "test_inputs = np.random.random((4, 2))\n",
    "\n",
    "test_forward_prop = forward_prop(test_inputs, test_thetas, 4)\n",
    "correct_forward_prop_val = [np.array([[1.24524706, 1.42359831], [1.34984787, 1.52210102], [0.58694045, 0.74140142], [0.66236153, 0.78210622]]), np.array([[1.54454925], [1.55730176], [1.43758967], [1.44616478]])]\n",
    "\n",
    "if not (test_forward_prop[0] - correct_forward_prop_val[0]).all():\n",
    "    print(\"Your first layer values are incorrect, sport\")\n",
    "elif not (test_forward_prop[1] - correct_forward_prop_val[1]).all():\n",
    "    print(\"Your second layer values are incorrect, ace\")\n",
    "else:\n",
    "    print(\"You did it, champ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method, `back_prop()` is an absolute banger, but easily the most important for neural networks to function. This method will take the derivative of each layer and then compute the gradients for each set of thetas\n",
    "\n",
    "You will need to complete the following steps:\n",
    "1. Calculate `diff3`, the difference of the `sigmoid()` of the last entry of `y_predictions`, and `y_actual`\n",
    "2. Calculate `diff2`, the multiplication of `diff2_unadjusted` and the `sigmoid_derivative()` of the first entry of \n",
    "`y_predictions`\n",
    "3. Calulate `delta_one`, the matrix multiplication of `diff2` and `format_partial_one` (Note the dimensions!)\n",
    "4. Calulate `delta_two`, the matrix multiplication of `diff3` and `format_partial_two` (Note the dimensions!)\n",
    "\n",
    "This method is fairly difficult to complete, so within every hint, you have the option to see the solution for the step\n",
    "\n",
    "Note: Unlike `forward_prop()`, this method is very difficult to code so that it works for any-sized neural network. Hence, we will hard code it with the assumption that there are 2 layers for our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hint for Step 1</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>The last entry of <code>y_predictions</code> is <code>y_predictions[-1]</code></li>  \n",
    "</ul>\n",
    "    <details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution for Step 1</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    Set <code>diff3 = sigmoid(y_predictions[-1]) - y_actual</code>\n",
    "</ul>\n",
    "</p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints for Step 2</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>You will need <code>np.multiply()</code> to multiply the two values</li>  \n",
    "    <li>The first value to multiply should be <code>diff2_unadjusted</code></li> \n",
    "    <li>The second value to multiply should be <code>sigmoid_derivative(y_predictions[0])</code></li> \n",
    "</ul>\n",
    "    <details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution for Step 2</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    Set <code>diff2 = np.multiply(diff2_unadjusted, sigmoid_derivative(y_predictions[0]))</code>\n",
    "</ul>\n",
    "</p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints for Step 3</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use <code>@</code>, <b>NOT</b> <code>np.multiply()</code></li>  \n",
    "    <li>You need to multiply <code>diff2.T</code> and <code>format_partial_one</code></li> \n",
    "</ul>\n",
    "    <details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution for Step 3</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    Set <code>delta_one = diff2.T @ format_partial_one</code>\n",
    "</ul>\n",
    "</p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints for Step 4</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>This step is almost identical to step 2!</li>  \n",
    "    <li>Use <code>@</code>, <b>NOT</b> <code>np.multiply()</code></li>  \n",
    "    <li>You need to multiply <code>diff3.T</code> and <code>format_partial_two</code></li> \n",
    "</ul>\n",
    "    <details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution for Step 4</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    Set <code>delta_two = diff3.T @ format_partial_two</code>\n",
    "</ul>\n",
    "</p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(y_predictions, y_actual, inputs, thetas, m, num_classifications):\n",
    "    # sets the constant for ones_col\n",
    "    ones_col = np.ones((m, 1))\n",
    "    \n",
    "    # adjusts the value of actual_val if there are more than 2 classifications\n",
    "    if (num_classifications > 2):\n",
    "        y_actual = (np.eye(num_classifications))[y_actual]\n",
    "    \n",
    "    # calculates the \"difference\" for the final layer\n",
    "    diff3 = ...\n",
    "    \n",
    "    # calculates the \"difference\" for the penultimate layer\n",
    "    diff2_unadjusted = diff3 @ thetas[1][:, 1:]\n",
    "    diff2 = ...\n",
    "    \n",
    "    # formats the partial derivatives\n",
    "    format_partial_one = np.hstack((ones_col, np.asarray(inputs)))\n",
    "    format_partial_two = np.hstack((ones_col, np.asarray(sigmoid(y_predictions[0]))))\n",
    "    \n",
    "    # calculates the unadjusted partial derivatives\n",
    "    delta_one = ...\n",
    "    delta_two = ...\n",
    "    \n",
    "    # returns our partial derivatives\n",
    "    return [delta_one / m, delta_two / m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test back_prop\n",
    "np.random.seed(123456789)\n",
    "\n",
    "test_thetas = [np.random.random((2, 3)), np.random.random((1, 3))]\n",
    "test_inputs = np.random.random((4, 2))\n",
    "test_y_actual = np.random.random((4, 1))\n",
    "\n",
    "test_back_prop = back_prop(test_forward_prop, test_y_actual, test_inputs, test_thetas, 4, 2)\n",
    "correct_back_prop = [np.array([[0.00907003, 0.0054814 , 0.00563069], [0.03581553, 0.02146392, 0.021947  ]]), np.array([[0.33095398, 0.25353556, 0.26271239]])]\n",
    "\n",
    "if not (test_back_prop[0] - correct_back_prop[0]).any():\n",
    "    print(\"Homie, your first partial derivative is wrong\")\n",
    "elif not (test_back_prop[1] - correct_back_prop[1]).any():\n",
    "    print(\"Oh no no your second partial derivative is wrong\")\n",
    "else:\n",
    "    print(\"I can't believe you actually did it you're insane!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using our Neural Network Architecture\n",
    "\n",
    "### Note: You don't have to code for the rest of the notebook! You can relax and watch your hard work pay off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the two needed functions for neural networks, we can start predicting stuff!\n",
    "\n",
    "We'll start by predicting the `xnor` operator, which essentially checks if two boolean inputs are equivalent\n",
    "\n",
    "We can use the following truth table to describe `xnor`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| a | b | out |\n",
    "| - | - | --- |\n",
    "| 1 | 1 |  1  |\n",
    "| 1 | 0 |  0  |\n",
    "| 0 | 1 |  0  |\n",
    "| 0 | 0 |  1  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picture below represents our neural network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"./xnor.png\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define our inputs and outputs, as well as our values for theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining inputs and outputs\n",
    "xnor_inputs = np.array([[1, 1, 0, 0], [1, 0, 1, 0]]).T\n",
    "xnor_outputs = np.array([[1, 0, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining theta values with correct dimensions\n",
    "xnor_thetas = [np.random.random((2, 3)), np.random.random((1, 3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll define constants for our gradient descent algorithm\n",
    "\n",
    "You might notice that `learning_rate` $ > 1$ Why?\n",
    "\n",
    "This is undoubtably because I messed up my code somewhere but I have no idea why this happens. All I know is that this is the value that makes gradient descent work\n",
    "\n",
    "It probably has to do with the fact that the sample size is so small, so we need to converge much quicker than normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constants\n",
    "sample_size = xnor_inputs.shape[0]\n",
    "num_classifications = 2\n",
    "learning_rate = 5\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run gradient descent for our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "for iteration in range(num_iterations):\n",
    "    # calculate the outputs for the iteration\n",
    "    outputs = forward_prop(xnor_inputs, xnor_thetas, sample_size)\n",
    "    # calculate the gradients for the iteration\n",
    "    gradients = back_prop(outputs, xnor_outputs, xnor_inputs, xnor_thetas, sample_size, num_classifications)\n",
    "    # adjust both of our thetas, taking a small step towards the minimum\n",
    "    xnor_thetas[0] = xnor_thetas[0] - learning_rate * gradients[0]\n",
    "    xnor_thetas[1] = xnor_thetas[1] - learning_rate * gradients[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to check your code!\n",
    "print(\"Inputs:\")\n",
    "print(str(xnor_inputs))\n",
    "print(\"--------\")\n",
    "print(\"Outputs (rounded):\")\n",
    "print(str(np.round(sigmoid(outputs[-1]), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you'll see that the outputs read\n",
    "\n",
    "$\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix}$\n",
    "\n",
    "which matches our data table!\n",
    "\n",
    "If it does, you just successfuly created a neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b: Recognizing Handwritten Digits\n",
    "\n",
    "Let's look at a common application of neural networks, image processing\n",
    "\n",
    "In the following cells, we'll write code to recognize handwritten digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network for this scenario is a little more complex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"./mnist.png\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: In order to continue, you need to complete the following steps in the `Anaconda Prompt`\n",
    "1. Open `Anaconda Prompt`\n",
    "2. `conda install pip`\n",
    "3. `pip install --upgrade tensorflow`\n",
    "4. `pip install Keras`\n",
    "5. `conda create -n mnist tensorflow keras`\n",
    "6. `conda activate mnist`\n",
    "7. `conda install jupyter`\n",
    "8. `conda list` - verify that you see numpy, keras, and tensorflow\n",
    "9. run `jupyter notebook` and open this file again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need an additional library, `keras`, to import our `mnist` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the appropriate libraries\n",
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import our testing and training sets (this might take a couple of seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data set\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll define our constants for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our constants\n",
    "num_classifications = 10\n",
    "m = 12000\n",
    "learning_rate = 2.5\n",
    "num_iterations = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to perform some additional calculations to transform our data:\n",
    "1. Reshape our data so that each image is represented as a single array of numbers\n",
    "2. Divide these numbers by 255 so the data is `normalized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping and normalizing the inputs to fit our needs\n",
    "mnist_train_inputs = (mnist_x_train[0:m][:][:].reshape(m, 28*28)) / 255\n",
    "mnist_train_outputs = mnist_y_train[0:m]\n",
    "\n",
    "mnist_test_inputs = (mnist_x_test[:][:][:].reshape(mnist_x_test.shape[0], 28*28)) / 255\n",
    "mnist_test_outputs = mnist_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define our thetas with the correct dimensions, randomizing them to avoid `computational symmetry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining theta values with correct dimensions\n",
    "theta_one = np.matrix(np.random.random((25, 785))) - 0.5\n",
    "theta_two = np.matrix(np.random.random((10, 26))) - 0.5\n",
    "mnist_thetas = [theta_one, theta_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, we're only using **20%** of the datset, and only iterating **500** times\n",
    "\n",
    "If we had more time and computational power, we could use our neural network with 100% of the datset and many many more iterations\n",
    "\n",
    "### Note: This cell might take ~ 1 to 3 min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "for iteration in range(num_iterations):\n",
    "    # calculate our outputs\n",
    "    outputs = forward_prop(mnist_train_inputs, mnist_thetas, m)\n",
    "    # calculate the gradients\n",
    "    gradients = back_prop(outputs, mnist_train_outputs, mnist_train_inputs, mnist_thetas, m, num_classifications)\n",
    "    # adjust our thetas accordingly\n",
    "    mnist_thetas[0] = mnist_thetas[0] - learning_rate * gradients[0]\n",
    "    mnist_thetas[1] = mnist_thetas[1] - learning_rate * gradients[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is trained, let's its accuracy with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogate to get our predicted values\n",
    "predicted_train_outputs = np.argmax(sigmoid(outputs[-1]), axis = 1)\n",
    "num_correct_labels = np.sum(np.diagonal(predicted_train_outputs == mnist_train_outputs))\n",
    "\n",
    "print(str(num_correct_labels) + \" out of \" + str(predicted_train_outputs.size) + \" images were identified correctly in training\")\n",
    "print(\"This is about \" + str(round(100 * (num_correct_labels / predicted_train_outputs.size), 5)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good that our model can predict values in the training set, but the accuracy of the test set is much more important. If we show the computer every possible image, it could simply \"memorize\" the inputs and then \"predict\" the correct output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict our test values\n",
    "test_predictions = sigmoid((forward_prop(mnist_test_inputs, mnist_thetas, mnist_x_test.shape[0]))[-1])\n",
    "# get the number by finding the max value\n",
    "predicted_test_output_labels = np.argmax(test_predictions, axis = 1)\n",
    "# add the number that are correct\n",
    "num_correct_test_labels = np.sum(np.diagonal(predicted_test_output_labels == mnist_test_outputs))\n",
    "\n",
    "print(str(num_correct_test_labels) + \" out of \" + str(predicted_test_output_labels.size) + \" images were identified correctly in testing\")\n",
    "print(\"This is about \" + str(round(100 * (num_correct_test_labels / predicted_test_output_labels.size),4)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above 90% isn't that bad! Especially since we're only using 20% of the dataset and less iterations. With more training samples and time to train, this model would be able to do a pretty good job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Predicting Handwritten Digits (Visualized)\n",
    "\n",
    "In the next cell, you'll be able to pick a random image from the testing data set and see what the computer predicts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: To run these next cells, you need to run one more command in `Anaconda Prompt` (sorry!)\n",
    "\n",
    "1. Open `Anaconda Prompt`\n",
    "2. Make sure you're in the mnist environment - `(mnist) C:\\...`\n",
    "3. `conda install -c anaconda pillow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the appropriate library\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num():\n",
    "    # help from: https://stackoverflow.com/questions/38867869/how-to-create-image-from-numpy-float32-array\n",
    "    # generates the random index from the list of test outputs\n",
    "    random_index = round(mnist_test_outputs.size * np.random.random())\n",
    "\n",
    "    # displays and formats the image correctly\n",
    "    data = mnist_test_inputs[random_index].reshape(28, 28)\n",
    "    formatted = (data * 255 / np.max(data)).astype('uint8')\n",
    "    img = Image.fromarray(formatted)\n",
    "    display(img.resize((256,256), PIL.Image.LANCZOS))\n",
    "\n",
    "    # calculates the predction values and label for that image\n",
    "    prediction_arr = np.round(sigmoid(forward_prop(np.matrix(mnist_test_inputs[random_index]), mnist_thetas, 1)[-1]), 3)\n",
    "    prediction_label = np.argmax(prediction_arr)\n",
    "\n",
    "    print(\"The prediction values are: \" + str(prediction_arr[0]))\n",
    "    print(\"The computer predicts this number is: \" + str(prediction_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep running this cell to see the computer predict numbers!\n",
    "predict_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the prediction values to see what the computer is thinking. The values that are higher and closer to 1 are the numbers that the computer most likely thinks the number is. Keep running the above cell to generate random numbers from the testing set!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
